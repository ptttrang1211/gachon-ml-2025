{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Convolution Neural Network**\n"
      ],
      "metadata": {
        "id": "3g3yQqxBnXOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "- 💡 **NOTE**\n",
        "    - 이 노트북의 코드를 실행하려면 GPU를 사용하는 것이 좋습니다. 구글 코랩에서는 **런타임 > 런타임 유형 변경 > 하드웨어 가속기 > T4 GPU**를 선택하세요.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DLl8lovjBLgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **(코랩에서)한글폰트 설치하기**"
      ],
      "metadata": {
        "id": "QzoHohTZbhQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n",
        "# 런타입 > 세션 다시 시작"
      ],
      "metadata": {
        "id": "b1HbwmIhbgiR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 한글 폰트 경로 설정\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "# matplotlib에서 기본 폰트로 지정\n",
        "plt.rcParams['font.family'] = 'NanumGothic'"
      ],
      "metadata": {
        "id": "fmE1LQfU1QqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DvCxDJO_hj0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **주요 개념**"
      ],
      "metadata": {
        "id": "lTF_POLGxNr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CNN(Convolution Neural Network)**\n",
        "- **CNN은 이미지나 영상 데이터를 처리하기 위해 설계된 딥러닝 신경망 구조**\n",
        "- 이미지 속 특징(선, 모서리, 곡선, 패턴) 을 자동으로 추출\n",
        "- 컴퓨터 비전, 자율주행, 의료 영상 등 다양한 분야에 사용\n",
        "- Convolutional neural network는 수십 또는 수백 개의 계층을 가질 수 있으며, 각 계층은 영상의 서로 다른 특징을 검출함\n",
        "- 각 훈련 영상에 서로 다른 해상도의 필터가 적용되고, 컨벌루션된 각 영상은 다음 계층의 입력으로 사용됨\n",
        "- 필터(커널)는 밝기, 경계와 같이 매우 간단한 특징으로 시작하여 객체를 고유하게 정의하는 특징으로 복잡도를 늘려갈 수 있음"
      ],
      "metadata": {
        "id": "Lga6-mVhw8Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **커널(Kernel)**\n",
        "- 커널(kernel)은 필터(filter), 마스크(mask)와 같은 말\n",
        "- **커널의 기능**은 **이미지로부터 내가 원하는 정보(특징)만을 추출하는 것**\n",
        "- **커널**은 **이미지 데이터를 지정된 간격(stride)으로 움직이며 합성곱(convolution)을 수행**\n",
        "- 합성곱 연산을 통해 나온 결과가 **feature map**\n",
        "- 커널은 이미지의 특징을 찾아내기 위한 공용 파라미터임\n",
        "- 일반적으로 (2,2), (3,3) 등의 정사각 행렬으로 정의됨\n",
        "- CNN에서 학습의 대상은 필터 파라미터 임\n",
        "- 입력 데이터의 각각의 채널에서 지정된 간격으로 순회하며 합성곱을 하고 모든 채널의 합성곱의 합인 feature map이 출력으로 나옴"
      ],
      "metadata": {
        "id": "LiqCCRLivExO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8gHiUMvbyQvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **합성곱 연산**(Convolution 연산)"
      ],
      "metadata": {
        "id": "B9IuLHTh9tcQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0b312e9"
      },
      "source": [
        "### **벡터와 행렬**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "765b189d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# numpy에서 행벡터처럼 출력하기 = 1차 행렬\n",
        "data = [1,2,3]\n",
        "data1= np.array(data)\n",
        "print(data1)\n",
        "print(data1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e630e48"
      },
      "source": [
        "### **브로드 캐스트(broadcast)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee6d573d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.array([[1,2],[3,4]])\n",
        "print(data * 10)\n",
        "print('-'*30)\n",
        "\n",
        "data1 = np.array([[1,2],[3,4]])\n",
        "data2 = np.array([10,20])\n",
        "print(data1 * data2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84fb83bc"
      },
      "source": [
        "### **벡터의 내적**\n",
        "내적' 연산이 바로 CNN의 원리를 이루는 가장 핵심적인 연산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1ed67c9"
      },
      "outputs": [],
      "source": [
        "data1 = np.array([1,2,3])\n",
        "data2 = np.array([4,5,6])\n",
        "print(data1 @ data2)            # 벡터의 내적 : 특징 맵 (Feature Map)의 1개 픽셀 값\n",
        "print( np.dot(data1, data2) )\n",
        "print('-'*30)\n",
        "\n",
        "data1 = np.array([1,2])\n",
        "data2 = np.array([[1,1,1],[2,2,2]])\n",
        "print(data1 @ data2)\n",
        "print('-'*30)\n",
        "\n",
        "data1 = np.array([[1,1,1],[2,2,2]])\n",
        "data2 = np.array([1,2,3])\n",
        "print(data1 @ data2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6ac636d"
      },
      "source": [
        "### **[실습]  Numpy를 이용한 합성곱 연산**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9a25ea1a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def getFeatureMap(data, mask):\n",
        "    result = []\n",
        "    x, y   = np.shape(data)\n",
        "    fx, fy = np.shape(mask)\n",
        "    for i in range(x-fx+1):\n",
        "        for j in range(y-fy+1):\n",
        "            result.append((data[i:i+fy, j:j+fy] * mask).sum())\n",
        "\n",
        "    return np.array(result).reshape(2,2)\n",
        "\n",
        "\n",
        "# input array\n",
        "data = np.array([[1,2,2,0],\n",
        "              [0,1,2,3],\n",
        "              [1,0,1,2],\n",
        "              [2,3,0,1]])\n",
        "# convolution kernel(==filter,mask)\n",
        "mask = np.array([[0,0,0],\n",
        "              [0,1,0],\n",
        "              [0,0,0]])\n",
        "print(f'#input :\\n{data}')\n",
        "print(f'#convolution kernel:\\n{mask}')\n",
        "\n",
        "# Feature Map(합성곱결과) 만들기\n",
        "result = getFeatureMap(data, mask)\n",
        "print(f'#feature map:\\n{result}')\n",
        "\n",
        "# Feature Map에서 map pooling 값 없기\n",
        "print(f'#max pooling:\\n{np.max(result)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VLoXm--T9sGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Convolution 연산 실습**\n"
      ],
      "metadata": {
        "id": "_1gz6eWIRxRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **필터 1개 사용**"
      ],
      "metadata": {
        "id": "D285FtHYkhwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))  # 가로세로 크기 inch단위\n",
        "\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "\n",
        "ori_image = img.imread('/content/image.png')\n",
        "ax1.imshow(ori_image)\n",
        "\n",
        "print(ori_image.shape)\n",
        "# 원본 이미지의 shape : (429, 640, 3) => (height, width, color)"
      ],
      "metadata": {
        "id": "7E-YWlD5hvPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력이미지의 형태\n",
        "# (1, 429, 640, 3) => (이미지 개수, height, width, color)\n",
        "input_image = ori_image.reshape((1,) + ori_image.shape)\n",
        "input_image = input_image.astype(np.float32)\n",
        "print('Convolution input image.shape : {}'.format(input_image.shape))"
      ],
      "metadata": {
        "id": "1DbytOS_hvSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력이미지 channel 변경\n",
        "# (1, 429, 640, 1) => (이미지 개수, height, width, color)\n",
        "# slicing을 이용하여 첫번째 R(Red) 값만 이용\n",
        "channel_1_input_image = input_image[:,:,:,0:1]\n",
        "print('Channel 변경 input_image.shape : {}'.format(channel_1_input_image.shape))"
      ],
      "metadata": {
        "id": "j5uURSr6hvWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter\n",
        "# (3,3,1,1) => (filter height, filter width, filter channel, filter 개수)\n",
        "# weight = np.random.rand(3,3,1,1)\n",
        "weight = np.array([[[[-1]],[[0]],[[1]]],\n",
        "                   [[[-1]],[[0]],[[1]]],\n",
        "                   [[[-1]],[[0]],[[1]]]])\n",
        "print('적용할 filter shape : {}'.format(weight.shape))"
      ],
      "metadata": {
        "id": "DID2xFG6hvcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stride : 1 (가로1, 세로1)\n",
        "# padding = 'VALID'\n",
        "\n",
        "conv2d = tf.nn.conv2d(channel_1_input_image,\n",
        "                      weight,\n",
        "                      strides=[1,1,1,1],\n",
        "                      padding='VALID')\n",
        "\n",
        "conv2d_result = conv2d.numpy()\n",
        "\n",
        "print('Convolution 결과 shape : {}'.format(conv2d_result.shape))\n"
      ],
      "metadata": {
        "id": "-fDl5A1limuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래의 코드는 이미지가 1장이기 때문에 필요없다.\n",
        "# i = np.swapaxes(conv2d_result,0,3)    # (1, 424, 638, 1)\n",
        "#                                       # (이미지개수, height, weight, filter 수)\n",
        "#                                       # filter수만큼 loop 돌리기 위해 axes swap\n",
        "\n",
        "# for filter_idx, t_img in enumerate(i):\n",
        "#     ax2.imshow(t_img)\n",
        "\n",
        "ax1.imshow(ori_image)\n",
        "\n",
        "t_img = conv2d_result[0,:,:,:]\n",
        "ax2.imshow(t_img, cmap='gray')\n",
        "\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4pcd5s2Cim2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC1fbiC9pVyo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))  # 가로세로 크기 inch단위\n",
        "\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "\n",
        "ori_image = img.imread('/content/image.png')\n",
        "ax1.imshow(ori_image)\n",
        "\n",
        "# 원본 이미지의 shape : (429, 640, 3) => (height, width, color)\n",
        "\n",
        "# 입력이미지의 형태\n",
        "# (1, 429, 640, 3) => (이미지 개수, height, width, color)\n",
        "input_image = ori_image.reshape((1,) + ori_image.shape)\n",
        "input_image = input_image.astype(np.float32)\n",
        "print('Convolution input image.shape : {}'.format(input_image.shape))\n",
        "\n",
        "# 입력이미지 channel 변경\n",
        "# (1, 429, 640, 1) => (이미지 개수, height, width, color)\n",
        "# slicing을 이용하여 첫번째 R(Red) 값만 이용\n",
        "channel_1_input_image = input_image[:,:,:,0:1]\n",
        "print('Channel 변경 input_image.shape : {}'.format(channel_1_input_image.shape))\n",
        "\n",
        "\n",
        "# filter\n",
        "# (3,3,1,1) => (filter height, filter width, filter channel, filter 개수)\n",
        "# weight = np.random.rand(3,3,1,1)\n",
        "weight = np.array([[[[-1]],[[0]],[[1]]],\n",
        "                   [[[-1]],[[0]],[[1]]],\n",
        "                   [[[-1]],[[0]],[[1]]]])\n",
        "# weight = np.array([[[[-2]],[[0]],[[1]]],\n",
        "#                    [[[-2]],[[0]],[[1]]],\n",
        "#                    [[[-2]],[[0]],[[1]]]])\n",
        "print('적용할 filter shape : {}'.format(weight.shape))\n",
        "\n",
        "# stride : 1 (가로1, 세로1)\n",
        "# padding = 'VALID'\n",
        "\n",
        "conv2d = tf.nn.conv2d(channel_1_input_image,\n",
        "                      weight,\n",
        "                      strides=[1,1,1,1],\n",
        "                      padding='VALID')\n",
        "\n",
        "conv2d_result = conv2d.numpy()\n",
        "\n",
        "print('Convolution 결과 shape : {}'.format(conv2d_result.shape))\n",
        "\n",
        "# 아래의 코드는 이미지가 1장이기 때문에 필요없다.\n",
        "# i = np.swapaxes(conv2d_result,0,3)    # (1, 424, 638, 1)\n",
        "#                                       # (이미지개수, height, weight, filter 수)\n",
        "#                                       # filter수만큼 loop 돌리기 위해 axes swap\n",
        "\n",
        "# for filter_idx, t_img in enumerate(i):\n",
        "#     ax2.imshow(t_img)\n",
        "\n",
        "t_img = conv2d_result[0,:,:,:]\n",
        "ax2.imshow(t_img, cmap='gray')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **필터 여러 개 사용** : (3개)"
      ],
      "metadata": {
        "id": "VDURpb7Nkn0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))  # 가로세로 크기 inch단위\n",
        "\n",
        "ax1 = fig.add_subplot(1,4,1)\n",
        "ax2 = fig.add_subplot(1,4,2)\n",
        "ax3 = fig.add_subplot(1,4,3)\n",
        "ax4 = fig.add_subplot(1,4,4)\n",
        "\n",
        "ori_image = img.imread('./image.png')\n",
        "ax1.imshow(ori_image)\n",
        "\n",
        "# 원본 이미지의 shape : (429, 640, 3) => (height, width, color)\n",
        "\n",
        "# 입력이미지의 형태\n",
        "# (1, 429, 640, 3) => (이미지 개수, height, width, color)\n",
        "input_image = ori_image.reshape((1,) + ori_image.shape)\n",
        "input_image = input_image.astype(np.float32)\n",
        "print('Convolution input image.shape : {}'.format(input_image.shape))\n",
        "\n",
        "# 입력이미지 channel 변경\n",
        "# (1, 429, 640, 1) => (이미지 개수, height, width, color)\n",
        "# slicing을 이용하여 첫번째 R(Red) 값만 이용\n",
        "channel_1_input_image = input_image[:,:,:,0:1]\n",
        "print('Channel 변경 input_image.shape : {}'.format(channel_1_input_image.shape))\n",
        "\n",
        "\n",
        "# filter\n",
        "# (3,3,1,3) => (filter height, filter width, filter channel, filter 개수)\n",
        "# weight = np.random.rand(3,3,1,3)\n",
        "weight = np.array([[[[-1,-1,-1]],[[0,0,-2]],[[1,1,-1]]],\n",
        "                   [[[-1,-2,0]],[[0,0,0]],[[1,2,0]]],\n",
        "                   [[[-1,-1,1]],[[0,0,2]],[[1,1,1]]]])\n",
        "\n",
        "print('적용할 filter shape : {}'.format(weight.shape))\n",
        "\n",
        "# 수직선을 강조하는 필터\n",
        "# [[-1, 0, 1],\n",
        "#  [-2, 0, 2]\n",
        "#  [-1, 0, 1]]\n",
        "\n",
        "# 수평선을 강조하는 필터\n",
        "# [[-1, -2, -1],\n",
        "#  [0, 0, 0]\n",
        "#  [1, 2, 1]]\n",
        "\n",
        "\n",
        "# stride : 1 (가로1, 세로1)\n",
        "# padding = 'VALID'\n",
        "\n",
        "conv2d = tf.nn.conv2d(channel_1_input_image,\n",
        "                      weight,\n",
        "                      strides=[1,1,1,1],\n",
        "                      padding='VALID')\n",
        "\n",
        "conv2d_result = conv2d.numpy()\n",
        "\n",
        "print('Convolution 결과 shape : {}'.format(conv2d_result.shape))\n",
        "\n",
        "# 아래의 코드는 이미지가 1장이기 때문에 필요없다.\n",
        "# i = np.swapaxes(conv2d_result,0,3)    # (1, 424, 638, 3)\n",
        "#                                       # (이미지개수, height, weight, filter 수)\n",
        "#                                       # filter수만큼 loop 돌리기 위해 axes swap\n",
        "\n",
        "# for filter_idx, t_img in enumerate(i):\n",
        "#     ax2.imshow(t_img)\n",
        "\n",
        "ax2.imshow(conv2d_result[0,:,:,0], cmap='gray')\n",
        "ax3.imshow(conv2d_result[0,:,:,1], cmap='gray')\n",
        "ax4.imshow(conv2d_result[0,:,:,2], cmap='gray')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1IGZCnduxnNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pooling 연산**\n",
        "\n",
        "- **특징 맵을 요약하여 공간 크기 감소 시키는 방식**\n",
        "- CNN 에서 pooling layer는 네트워크의 파라미터 갯수나 연산량을 줄이기 위해 input에서 spatial 하게 downsampling을 진행해 사이즈를 줄이는 역할을 합니다. 일반적으로 CNN에서는 Convolution layer 다음에 들어갑니다."
      ],
      "metadata": {
        "id": "q3yuQXGnmM1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))  # 가로세로 크기 inch단위\n",
        "\n",
        "ax1 = fig.add_subplot(1,3,1)\n",
        "ax2 = fig.add_subplot(1,3,2)\n",
        "ax3 = fig.add_subplot(1,3,3)\n",
        "\n",
        "ori_image = img.imread('/content/image.png')\n",
        "ax1.imshow(ori_image)\n",
        "\n",
        "# 원본 이미지의 shape : (429, 640, 3) => (height, width, color)\n",
        "\n",
        "# 입력이미지의 형태\n",
        "# (1, 429, 640, 3) => (이미지 개수, height, width, color)\n",
        "input_image = ori_image.reshape((1,) + ori_image.shape)\n",
        "input_image = input_image.astype(np.float32)\n",
        "print('Convolution input image.shape : {}'.format(input_image.shape))\n",
        "\n",
        "# 입력이미지 channel 변경\n",
        "# (1, 429, 640, 1) => (이미지 개수, height, width, color)\n",
        "# slicing을 이용하여 첫번째 R(Red) 값만 이용\n",
        "channel_1_input_image = input_image[:,:,:,0:1]\n",
        "print('Channel 변경 input_image.shape : {}'.format(channel_1_input_image.shape))\n",
        "\n",
        "\n",
        "# filter\n",
        "# (3,3,1,1) => (filter height, filter width, filter channel, filter 개수)\n",
        "# weight = np.random.rand(3,3,1,1)\n",
        "weight = np.array([[[[-1]],[[0]],[[1]]],\n",
        "                   [[[-1]],[[0]],[[1]]],\n",
        "                   [[[-1]],[[0]],[[1]]]])\n",
        "print('적용할 filter shape : {}'.format(weight.shape))\n",
        "\n",
        "# stride : 1 (가로1, 세로1)\n",
        "# padding = 'VALID'\n",
        "\n",
        "conv2d = tf.nn.conv2d(channel_1_input_image,\n",
        "                      weight,\n",
        "                      strides=[1,1,1,1],\n",
        "                      padding='VALID')\n",
        "\n",
        "conv2d_result = conv2d.numpy()\n",
        "\n",
        "print('Convolution 결과 shape : {}'.format(conv2d_result.shape))\n",
        "\n",
        "# 아래의 코드는 이미지가 1장이기 때문에 필요없다.\n",
        "# i = np.swapaxes(conv2d_result,0,3)    # (1, 424, 638, 1)\n",
        "#                                       # (이미지개수, height, weight, filter 수)\n",
        "#                                       # filter수만큼 loop 돌리기 위해 axes swap\n",
        "\n",
        "# for filter_idx, t_img in enumerate(i):\n",
        "#     ax2.imshow(t_img)\n",
        "\n",
        "t_img = conv2d_result[0,:,:,:]\n",
        "ax2.imshow(t_img, cmap='gray')\n",
        "\n",
        "#-----------------\n",
        "## pooling 처리 ##\n",
        "#-----------------\n",
        "# ksize = pooling filter의 크기(avg_pool)\n",
        "pool = tf.nn.max_pool(conv2d_result,\n",
        "                      ksize=[1,3,3,1],\n",
        "                      strides=[1,3,3,1],\n",
        "                      padding='VALID')\n",
        "\n",
        "pool_result = pool.numpy()\n",
        "print('Pooling한 결과 shape : {}'.format(pool_result.shape))\n",
        "\n",
        "t_img = pool_result[0,:,:,:]\n",
        "ax3.imshow(t_img, cmap='gray')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gDQxgp-0mNsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MNIST Data Set을 이용한 머신러닝 학습**(DNN)\n",
        "- regression 방식"
      ],
      "metadata": {
        "id": "eDYhWnesmOU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.preprocessing  import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# 1. Raw Data Loading\n",
        "df = pd.read_csv('./train.csv')\n",
        "# display(df.head())\n",
        "display(df.shape)"
      ],
      "metadata": {
        "id": "YQOynX81tk_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 데이터 전처리\n",
        "# - 결측치 처리\n",
        "# - 우리 데이터는 연습용 데이터로 결측치가 없음\n",
        "\n",
        "# - 이상치 처리(outlier 처리: z-score)\n",
        "# - 이상치도 없어요!\n",
        "\n",
        "# - 눈으로 데이터를 확인하고 갈겁니다.\n",
        "# pixel 데이터만 분리\n",
        "img_data = df.drop(columns=['label'], axis=1, inplace=False).values\n",
        "\n",
        "# label 데이터만 분리\n",
        "label_data = df['label']\n",
        "\n",
        "fig = plt.figure()  # 도화지 준비 : figsize=(10,10)\n",
        "# subplot이 들어간 list 생성\n",
        "fig_arr = []\n",
        "for n in range(10):\n",
        "    fig_arr.append(fig.add_subplot(2,5,n+1))\n",
        "    fig_arr[n].imshow(img_data[n].reshape(28,28),\n",
        "                      cmap='Blues', #gray\n",
        "                      interpolation='nearest')\n",
        "\n",
        "plt.tight_layout()  # layout을 알아서 잘 정리해서\n",
        "plt.show()\n",
        "# 숫자 이미지가 정상적으로 처리됨을 확인함."
      ],
      "metadata": {
        "id": "H56YASkztlCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Feature Engineering (학습이 적합한 방법으로 데이터를 변형하는 작업: 새로운 변수 추가)\n",
        "# 이미지인 경우 특별히 해야 할 일이 없음\n",
        "\n",
        "\n",
        "# 4. 독립면수와 종속변수를 분리\n",
        "x_data = df.drop('label', axis=1, inplace=False).values\n",
        "t_data = df['label'].values.reshape(-1,1)    # Series데이터를 2차원 데이터로 만든다. one-hot 인코딩 처리는 keras에게 맡깁니다.\n"
      ],
      "metadata": {
        "id": "45xabMA6tlF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Normalization(정규화) : Min-max(0~1), Standardization\n",
        "scaler = MinMaxScaler()     # scaler 객체 생성\n",
        "scaler.fit(x_data)          # scaler에게 최대, 최소값을 알려줘서 준비시켜줍니다.\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "# x_data_norm = scaler.fit.transform(x_data)"
      ],
      "metadata": {
        "id": "LgIQjFnmtlJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 학습데이터와 테스트데이터 분리\n",
        "x_train, x_test, t_train, t_test = train_test_split(x_data_norm,\n",
        "                                                    t_data,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "\n",
        "# 7. 모델 구현\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(784,)))  # input_layer\n",
        "model.add(Dense(units=256, activation='relu'))   # hidden_layer\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax')) # output_layer\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])       # 평가 기준\n",
        "\n",
        "model.fit(x_train, t_train,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          batch_size=100,\n",
        "          validation_split=0.3)\n"
      ],
      "metadata": {
        "id": "SIOI9i_qtvBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **전체 코드**"
      ],
      "metadata": {
        "id": "xdEo8vmet9Ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.preprocessing  import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# 1. Raw Data Loading\n",
        "df = pd.read_csv('./train.csv')\n",
        "# display(df.head())\n",
        "display(df.shape)\n",
        "\n",
        "\n",
        "# 2. 데이터 전처리\n",
        "# - 결측치 처리\n",
        "# - 우리 데이터는 연습용 데이터로 결측치가 없음\n",
        "\n",
        "# - 이상치 처리(outlier 처리: z-score)\n",
        "# - 이상치도 없어요!\n",
        "\n",
        "# - 눈으로 데이터를 확인하고 갈겁니다.\n",
        "# pixel 데이터만 분리\n",
        "img_data = df.drop(columns=['label'], axis=1, inplace=False).values\n",
        "\n",
        "# label 데이터만 분리\n",
        "label_data = df['label']\n",
        "\n",
        "fig = plt.figure()  # 도화지 준비 : figsize=(10,10)\n",
        "# subplot이 들어간 list 생성\n",
        "fig_arr = []\n",
        "for n in range(10):\n",
        "    fig_arr.append(fig.add_subplot(2,5,n+1))\n",
        "    fig_arr[n].imshow(img_data[n].reshape(28,28),\n",
        "                      cmap='Blues', #gray\n",
        "                      interpolation='nearest')\n",
        "\n",
        "plt.tight_layout()  # layout을 알아서 잘 정리해서\n",
        "plt.show()\n",
        "# 숫자 이미지가 정상적으로 처리됨을 확인함.\n",
        "\n",
        "\n",
        "# 3. Feature Engineering (학습이 적합한 방법으로 데이터를 변형하는 작업: 새로운 변수 추가)\n",
        "# 이미지인 경우 특별히 해야 할 일이 없음\n",
        "\n",
        "\n",
        "# 4. 독립면수와 종속변수를 분리\n",
        "x_data = df.drop('label', axis=1, inplace=False).values\n",
        "t_data = df['label'].values.reshape(-1,1)    # Series데이터를 2차원 데이터로 만든다. one-hot 인코딩 처리는 keras에게 맡깁니다.\n",
        "\n",
        "\n",
        "# 5. Normalization(정규화) : Min-max(0~1), Standardization\n",
        "scaler = MinMaxScaler()     # scaler 객체 생성\n",
        "scaler.fit(x_data)          # scaler에게 최대, 최소값을 알려줘서 준비시켜줍니다.\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "# x_data_norm = scaler.fit.transform(x_data)\n",
        "\n",
        "\n",
        "# 6. 학습데이터와 테스트데이터 분리\n",
        "x_train, x_test, t_train, t_test = train_test_split(x_data_norm,\n",
        "                                                    t_data,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "\n",
        "# 7. 모델 구현\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(784,)))  # input_layer\n",
        "model.add(Dense(units=256, activation='relu'))   # hidden_layer\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax')) # output_layer\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])       # 평가 기준\n",
        "\n",
        "model.fit(x_train, t_train,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          batch_size=100,\n",
        "          validation_split=0.3)\n"
      ],
      "metadata": {
        "id": "84wkQKDF3HcQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MNIST Data Set을 이용한 CNN 학습**(CNN)\n",
        "- https://kr.mathworks.com/discovery/convolutional-neural-network.html?utm_source=chatgpt.com"
      ],
      "metadata": {
        "id": "qgkM-xulpVi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간이 오래 걸린다.\n",
        "# MNIST Data Set을 이용한 CNN 학습\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.preprocessing  import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# 1. Raw Data Loading\n",
        "df = pd.read_csv('./train.csv')\n",
        "# display(df.head())\n",
        "display(df.shape)\n",
        "\n",
        "\n",
        "# 2. 데이터 전처리\n",
        "# - 결측치 처리\n",
        "# - 우리 데이터는 연습용 데이터로 결측치가 없음\n",
        "\n",
        "# - 이상치 처리(outlier 처리: z-score)\n",
        "# - 이상치도 없어요!\n",
        "\n",
        "# - 눈으로 데이터를 확인하고 갈겁니다.\n",
        "# pixel 데이터만 분리\n",
        "img_data = df.drop(columns=['label'], axis=1, inplace=False).values\n",
        "\n",
        "# label 데이터만 분리\n",
        "label_data = df['label']\n",
        "\n",
        "fig = plt.figure()  # 도화지 준비 : figsize=(10,10)\n",
        "# subplot이 들어간 list 생성\n",
        "fig_arr = []\n",
        "for n in range(10):\n",
        "    fig_arr.append(fig.add_subplot(2,5,n+1))\n",
        "    fig_arr[n].imshow(img_data[n].reshape(28,28),\n",
        "                      cmap='gray', #Bules\n",
        "                      interpolation='nearest')\n",
        "\n",
        "plt.tight_layout()  # layout을 알아서 잘 정리해서\n",
        "plt.show()\n",
        "# 숫자 이미지가 정상적으로 처리됨을 확인함.\n",
        "\n",
        "\n",
        "# 3. Feature Engineering (학습이 적합한 방법으로 데이터를 변형하는 작업: 새로운 변수 추가)\n",
        "# 이미지인 경우 특별히 해야 할 일이 없음\n",
        "\n",
        "\n",
        "# 4. 독립면수와 종속변수를 분리\n",
        "x_data = df.drop('label', axis=1, inplace=False).values\n",
        "t_data = df['label'].values.reshape(-1,1)    # Series데이터를 2차원 데이터로 만든다. one-hot 인코딩 처리는 keras에게 맡깁니다.\n",
        "\n",
        "\n",
        "# 5. Normalization(정규화) : Min-max(0~1), Standardization\n",
        "scaler = MinMaxScaler()     # scaler 객체 생성\n",
        "scaler.fit(x_data)          # scaler에게 최대, 최소값을 알려줘서 준비시켜줍니다.\n",
        "x_data_norm = scaler.transform(x_data)\n",
        "# x_data_norm = scaler.fit.transform(x_data)\n",
        "\n",
        "\n",
        "# 6. 학습데이터와 테스트데이터 분리\n",
        "x_train, x_test, t_train, t_test = train_test_split(x_data_norm,\n",
        "                                                    t_data,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "\n",
        "# 7. 모델 구현(CNN : 4치원)\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32,\n",
        "                 kernel_size=(3,3),\n",
        "                 strides=(1,1),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1))) # input_shape: 이미지 한개의 사이즈(3차원)\n",
        "                 # 모델에 첫번째로 추가되는 layer는 input layer 성격을 갖고 있다.\n",
        "\n",
        "model.add(Conv2D(filters=64,\n",
        "                 kernel_size=(3,3),\n",
        "                 strides=(1,1),\n",
        "                 activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))   # 이미지를 반으로 나눈다.\n",
        "\n",
        "model.add(Conv2D(filters=128,\n",
        "                 kernel_size=(3,3),\n",
        "                 strides=(1,1),\n",
        "                 activation='relu'))\n",
        "# 필터의 갯수는 앞보다 뒷쪽의 conv layer filter의 갯수가 크다.\n",
        "# 왜냐하면 뒷쪽은 이미지 크기가 작아지기 때문에 filter의 갯수가 커진다.\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))   # 이미지를 반으로 나눈다.\n",
        "\n",
        "# model.summary()   # 모델의 구성을 확인하고 싶을 때 사용\n",
        "'''\n",
        "# output shape 설명\n",
        "(None, 26, 26, 32)\n",
        "None : 데이터가 아직 들어오지 않았음.\n",
        "26, 26, 32 : (32:(3x3)필터개수, stride=(1,1)기 때문에 26x26)\n",
        "\n",
        "#Params 설명:\n",
        "변수의 갯수\n",
        "'''\n",
        "# classification 작업 시작\n",
        "model.add(Flatten())\n",
        "# model.summary()\n",
        "\n",
        "model.add(Dense(units=256,\n",
        "                activation='relu'))   # hidden_layer\n",
        "# cnn에서는 hidden layer를 1개 정도로 적게 사용한다.\n",
        "\n",
        "\n",
        "model.add(Dense(units=10,\n",
        "                activation='softmax')) # output_layer\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])       # 평가 기준\n",
        "\n",
        "model.fit(x_train.reshape(-1,28,28,1),\n",
        "          t_train,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          batch_size=100,\n",
        "          validation_split=0.3)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d0YnHwy0YPZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **결론** :"
      ],
      "metadata": {
        "id": "DNio5g_3rRZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습을 많이 하면 할 수록 **Filter가 좋아진다**.-> 좋은 모델이 된다.\n",
        "- 그렇기 때문에 다른 모델에서는 좋아진 Filter 부분만 가져오는 방법을 사용하고 즉, **Feature Extraction 부분을 가져다 사용함**.  이것이 바로 **전이학습(Transfer Learning)**이라고 한다.  --> LesNet GoogleNet 등등 ,\n"
      ],
      "metadata": {
        "id": "rfDeYyMfrPgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 좀 더 좋아지기 위해서 기존에 전이학습된 필터는 수정을 안했으나, 좀 더 좋은 성능을 내기 위해 가져온 Feature Extraction 부분 중 **특정 필터(마지막 필터)는 수정**을 하여 나에게 적당한 방법으로 적용하는 방법이 있으며, 이것을 **파인 튜닝**(Fine Tunning)이라고 한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "40a6jJkFrS8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 좋은 Transfer learning model을 사용하려면\n",
        "    - 내 이미지에 맞는 적합한 모델을 사용하는 것이 중요하다.  "
      ],
      "metadata": {
        "id": "0gPbZHkmrccu"
      }
    }
  ]
}