{"cells":[{"cell_type":"markdown","source":["# **LangChain과 RAG로 챗봇 만들기**\n","\n","\n"],"metadata":{"id":"FyM74B4QApqt"}},{"cell_type":"markdown","source":["---\n","\n","## **실습 환경**\n","\n","- **구글 코랩 + OpenAI API Key**\n","\n","\n","---\n"],"metadata":{"id":"JqytTMjwstJC"}},{"cell_type":"markdown","source":["# **1.RAG 이해**"],"metadata":{"id":"hs8UCbj3sU3l"}},{"cell_type":"markdown","source":["## **1-1.검색 증강 생성(RAG)의 개념**"],"metadata":{"id":"WnsXCTYGsh59"}},{"cell_type":"markdown","source":["### **임베딩의 이해**"],"metadata":{"id":"g7rxBBchsvIL"}},{"cell_type":"code","source":[],"metadata":{"id":"5QZb094KTfAY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **임베딩(Embedding)**\n","    - **텍스트**를 숫자가 나열된 **벡터(Vector)로 변환**하는 것\n","    - 텍스트 임베딩 후 **텍스트 간의 유사도**를 구할 수 있음.\n","    - 다시 말해 **'검색어'가 들어오면 검색어와 연관된 '문서들을 찾는 '검색' 기능을 구현할 수 있다**.\n"],"metadata":{"id":"mUB4HltAtdzS"}},{"cell_type":"markdown","source":["- **임베딩 모델의 종류**\n","    - **오픈 모델**\n","        - 무료로 다운로드하여 사용\n","        - 모델을 실행할 수 있는 고성능 컴퓨터(GPU) 필요\n","        - **예: 공개 임베딩 모델 중 성능 좋은 bge-m3 모델 등(한글 가능)**\n","    - **API 모델**\n","        - 사용량에 따라 비용 발생\n","        - 고성능 컴퓨터 필요 없이 API 호출 방식으로 사용\n","        - **예: OpenAI에서 제공하는 유료 임베딩 API**\n","- **모델 종류 선택시 고려사항**\n","    - 각 **모델의 장단점을 비교**하여 **사용 목적에 맞게 선택**\n","    - 보안 등의 이슈가 있을 경우에는 API 모델 사용이 불가 (공공, 금융 등)"],"metadata":{"id":"j0TqgKhswR5y"}},{"cell_type":"markdown","source":["### **검색기의 이해**\n","- 참고 : https://medium.com/@serkan_ozal/vector-similarity-search-53ed42b951d9\n","\n","- <mark>**텍스트 임베딩 후 임베딩 벡터 간의 유사도를 구할 수 있으며, 이를 이용해 '검색기'를 구현한다**.</mark>\n","\n","- <img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/0*f53uQ4clZAE5DoAP\" width=\"400\">\n","\n","- **코사인 유사도 공식**\n","    - 벡터와 벡터간의 유사도를 비교할 때 두 벡터 간으 사잇각을 구해서 얼마나 유사한지 수치로 나타낸 것\n","$similarity=cos(Θ)=\\frac{A⋅B}{||A||\\ ||B||}=\\frac{\\sum_{i=1}^{n}{A_{i}×B_{i}}}{\\sqrt{\\sum_{i=1}^{n}(A_{i})^2}×\\sqrt{\\sum_{i=1}^{n}(B_{i})^2}}$\n","    - 챗봇 규현시에 식을 외울 필요는 없다.\n","\n","- **작업 순서**\n","    1. 기존에 가지고 있는 **모든 문서를 임베딩하여 벡터로 변환**\n","    2. 새롭게 **입력된 텍스트를 임베딩하여 벡터로 변환**\n","    3. 새롭게 생성된 벡터와 기존 문서의 **벡터 간 유사도를 측정**하여 **가장 유사한 몇개의 문서만 출력** --> 단어가 겹치지 않아도 유사도가 높을 수 있다.\n","\n","- **임베딩 기반 검색의 장점**\n","    - **단어 일치가 없어도 검색 가능** : 의미가 유사한 문서를 찾을 수 잇음\n","    - **유연한 검색**: 다양한 표현으로 검색해도 관련된 결과를 얻을 수 있음\n","    - **문맥 이해**: 단어의 의미뿐만 아니라 문맥까지 고려하여 검색"],"metadata":{"id":"T-gy1ryHxJDi"}},{"cell_type":"markdown","source":["### **RAG 기반 챗봇 예시**\n","\n","- **동작 절차**\n","    - 서울시 청년 정책 문서를 가져와서\n","    - 문서에 대한 임베딩을 미리 진행해 둠(57개 문서)\n","    - 검색어(질문: '신혼부부 임차보증금 지원 정책이 궁금해')를 넣으면 그 즉시 유사도 계산 --> 1 : 57의 유사도 계산\n","    - 유사도가 가장 높은 Top3 문서만 가져옴\n","    - ChatGPT와 같은 영리한 모델에게 질문하면서 Top3 문서와 질문 참고해서 대답하도록 구성하다.\n","\n","- **검색 증강 생성(RAG) 기반 챗봇의 장점**\n","    - 외부 데이터베이스가 지속적으로 업데이트되기 때문에 항상 최신 정보를 바탕으로 답변을 생성할 수 있음\n","    - 실제 데이터를 기반으로 답변을 생성하기 때문에 사실과 다른 정보를 제공할 가능성이 낮음(할루시네이션 현상 감소)"],"metadata":{"id":"eYEdvleV1iBI"}},{"cell_type":"markdown","source":["### **벡터 데이터베이스의 이해**\n","\n","- **벡터 데이터베이스(Vector Database)**\n","    - **벡터(숫자들의 나열)을 저장하는 저장소**\n","    - 벡터를 저장, 관리, 검색(유사성 기반)하는 일\n","    - 코사인 유사도와 같은 **유사성 검색을 기반으로 상위 N개의 벡터를 반환**\n","\n","- **벡터 데이터베이스의 종류**\n","\n","| 구분 | 특징 | 장점 | 단점 |\n","|------|------|------|------|\n","| 파인콘 | - 간단한 API<br>- 빠른 검색 성능<br>- 오픈소스가 아님(비용 부담) | - 클라우드 기반으로 쉬운 확장성<br>- 높은 보안 | - 상대적으로 제어하는 것이 제한될 수 있음<br>- 오픈소스가 아니므로 외존성이 있음 |\n","| **밀버스** (익숙해지면 권장) | - 고성능 오픈소스 | - 무료로 사용 가능 | - 꾸준한 관리와 유지보수 필요 |\n","| 쿼드란트 | - 고성능 오픈소스 | - 복잡한 검색 쿼리에 대한 지원 | - 잘 알려지지 않아서 커뮤니티의 협의 미비<br>- 밀버스나 엘라스틱 서브보다 작음 |\n","| **크로마** (권장) | - LLM을 위한 벡터 데이터베이스 | - 텍스트 데이터에 언어 모델에 맞춤<br>- 무료로 사용 가능 | - 이미지나 오디오 데이터 같은 다른 유형의 벡터 데이터 처리에는 덜 최적화 |\n","| 엘라스틱서치 | - 전통적인 키워드 검색도 지원<br>- 오픈소스가 아님(비용 부담) | - 다양한 추가 기능 | - 벡터 검색이 다른 전문 벡터 DB에 비해 강력하지 않을 수 있음 |\n","| **파이스** (DB라기보다는 인덱스임. 권장) | - 고성능 오픈소스<br>- GPU에 올릴 수 있음 | - 무료로 사용 가능 | - 인덱스에 대한 공부가 필요<br>- 초보자에게는 다소 어려움 |\n","\n"],"metadata":{"id":"RCOEMyZk3j_Z"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"cWZvYQvE6SpE"}},{"cell_type":"markdown","source":["## **1-2.OpenAI API Key 발급 방법**"],"metadata":{"id":"60FhH_ulsoS8"}},{"cell_type":"markdown","source":["### **API Key 발급 단계** -  **(5$ 필요!)**\n","- https://platform.openai.com/docs/overview 접속\n","    - 회원가입(Sign up) 및 로그인\n","- https://platform.openai.com/api-keys  이동\n","    - **[+Create new secret key]** 클릭\n","    - name에 키 이름 넣고**(예: test_key)**\n","    - **[Copy]** 클릭 키를 메모장에 복사해 놓는다. --> 이 키로 과금이 된다.\n","    - **[View user API keys]** 클릭\n","    - 좌측 메뉴에 **Billing** 선택\n","    - **[Add payment details]** 선택 --> **카드 등록, 5$ 결재**"],"metadata":{"id":"xD1idP759Rwq"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"CsIetSprd_Oj"}},{"cell_type":"markdown","source":["# **2. PDF 문서 기반의 챗봇 구축**"],"metadata":{"id":"PJWNGrppA7GL"}},{"cell_type":"markdown","source":["- **프로젝트 목표**\n","    - **금융(경제)용어에 대한 설명을 답변하는 챗봇**\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"Pup5rPDgUL5b"}},{"cell_type":"markdown","source":["## **2-1.PDF 파일 전처리**"],"metadata":{"id":"B-XW7ljrW35w"}},{"cell_type":"markdown","source":["  \n","    \n","    \n","- **작업 내용**\n","    1. **langchain, tiktoken, pypdf 등 실습을 위한 패키지 설치**\n","    2. **PDF 전처리 - 분할**\n","        - PDF 파일을 다운로드하고 랭체인을 이용하여 챗봇 학습에 적합한 형태로 전처리할 수 있다.\n","            - **페이지별로 분할하고 텍스트 추출**\n","            - **빈페이지는 자동으로 삭제**\n","    3. **PDF 전처리 - 정제**\n","        - PDF 파일의 불필요한 정보(머릿말, 목차 등)를 삭제하여 **데이터를 정체**할 수 있다."],"metadata":{"id":"WSPC05pkOH_H"}},{"cell_type":"markdown","metadata":{"id":"2wMlmQyBiH5e"},"source":["- [참고] 벡터DB 사용하기:\n","    - https://drive.google.com/file/d/12V1FKr65t8mKiEDThSUoX34p0gKhmuRH/view?usp=drive_link"]},{"cell_type":"markdown","source":["### **필요 라이브러리 설치**"],"metadata":{"id":"4uwqM-QuYSxO"}},{"cell_type":"code","source":["!pip install -qU \\\n","  langchain tiktoken openai pypdf chromadb langchain_community langchain_openai \\\n","  \"requests==2.32.4\" \\\n","  \"opentelemetry-api==1.37.0\" \"opentelemetry-sdk==1.37.0\" \\\n","  \"opentelemetry-proto==1.37.0\" \\\n","  \"opentelemetry-exporter-otlp-proto-common==1.37.0\" \\\n","  \"opentelemetry-exporter-otlp-proto-grpc==1.37.0\" \\\n","  \"opentelemetry-exporter-otlp-proto-http==1.37.0\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dr5BgoVNBvZW","executionInfo":{"status":"ok","timestamp":1761379842448,"user_tz":-540,"elapsed":80919,"user":{"displayName":"Joys","userId":"08210666431620526411"}},"outputId":"0d329138-526d-4797-edd9-b09bc7ce1fd0","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rwEv1No4k3Zv","collapsed":true},"outputs":[],"source":["# !pip install -qU langchain tiktoken openai pypdf chromadb langchain_community langchain_openai \\"]},{"cell_type":"code","source":["# ERROR 발생시 : google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5\n","# 1) requests를 Colab이 요구하는 버전으로 맞춤\n","# 예: chromadb를 설치하되, requests는 2.32.4로 고정\n","# %pip install -q \"chromadb==1.0.21\" \"requests==2.32.4\""],"metadata":{"id":"tmvVW9pRQK72"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2) (선택) 의존성 검사로 충돌 확인\n","%pip check"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OF766qDaQMK5","executionInfo":{"status":"ok","timestamp":1761380089938,"user_tz":-540,"elapsed":1913,"user":{"displayName":"Joys","userId":"08210666431620526411"}},"outputId":"776316ec-1ecb-4add-c896-a356b6d399fa"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["ipython 7.34.0 requires jedi, which is not installed.\n"]}]},{"cell_type":"code","source":["# 설치된 특정 라이브러리 버전 확인\n","%pip list | grep -E 'langchain|tiktoken|openai|pypdf|chromadb'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yLqoHwgVLk0","executionInfo":{"status":"ok","timestamp":1761380093352,"user_tz":-540,"elapsed":1709,"user":{"displayName":"Joys","userId":"08210666431620526411"}},"outputId":"d157660b-ab50-407f-81b1-ecabbbbdcadf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["chromadb                                 1.2.1\n","langchain                                0.3.27\n","langchain-community                      0.3.27\n","langchain-core                           0.3.79\n","langchain-openai                         0.3.35\n","langchain-text-splitters                 0.3.11\n","openai                                   2.6.1\n","pypdf                                    6.1.3\n","tiktoken                                 0.12.0\n"]}]},{"cell_type":"markdown","source":["### API 키 설정"],"metadata":{"id":"ejEGoJe-pLlI"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"RCjjH1gyiO3u","executionInfo":{"status":"ok","timestamp":1761380104514,"user_tz":-540,"elapsed":13,"user":{"displayName":"Joys","userId":"08210666431620526411"}}},"outputs":[],"source":["import os\n","# os.environ['OPENAI_API_KEY'] =  \"여러분들의 키 값\"\n","os.environ['OPENAI_API_KEY'] =  \"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\""]},{"cell_type":"markdown","metadata":{"id":"YAjSAYr5IheJ"},"source":["### **데이터 살펴보기**\n","\n","* 데이터는 한국은행에서 제공하는 '2020_경제금융용어 700선_게시.pdf'를 사용한다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmTDKGAGlio_"},"outputs":[],"source":["from langchain.vectorstores import Chroma\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain.chains import RetrievalQA\n","import urllib.request\n","from langchain.document_loaders import PyPDFLoader"]},{"cell_type":"code","source":["# 1) 표준 라이브러리\n","import os\n","import urllib.request\n","\n","# 2) 서드파티\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain_community.vectorstores import Chroma\n","from langchain_community.document_loaders import PyPDFLoade"],"metadata":{"id":"qCjzjq-dTBzS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PgN4yqWFJ49X"},"source":["https://www.bok.or.kr/portal/bbs/B0000249/view.do?nttId=235017&menuNo=200765  \n","\n","위 링크에서 pdf 파일을 다운로드 받아서 업로드합니다.  \n","\n","2020_경제금융용어 700선_게시.pdf"]},{"cell_type":"markdown","metadata":{"id":"WAfMtjt2aCha"},"source":["해당 파일을 열어서 확인하면 다음과 같습니다."]},{"cell_type":"markdown","metadata":{"id":"tlvnXVTQaVAa"},"source":["![](https://wikidocs.net/images/page/215361/%EC%BA%A1%EC%B2%98%EC%9D%B4%EB%AF%B8%EC%A7%80.PNG)"]},{"cell_type":"markdown","metadata":{"id":"b5xlmIVUi0e3"},"source":["PDF를 로드하여 여러 개의 문서로 분할해주는  \n","\n","```from langchain.document_loaders import PyPDFLoader```를 사용합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBfTLKiBRIRE"},"outputs":[],"source":["# !wget -O \"2020_경제금융용어 700선_게시.pdf\" \"https://www.bok.or.kr/portal/cmmn/file/fileDown.do?menuNo=200765&atchFileId=KO_00000000000142606&fileSn=1\"\n","urllib.request.urlretrieve(\"https://github.com/chatgpt-kr/openai-api-tutorial/raw/main/ch07/2020_%EA%B2%BD%EC%A0%9C%EA%B8%88%EC%9C%B5%EC%9A%A9%EC%96%B4%20700%EC%84%A0_%EA%B2%8C%EC%8B%9C.pdf\", filename=\"2020_경제금융용어 700선_게시.pdf\")"]},{"cell_type":"markdown","metadata":{"id":"MfIhk0mbiojI"},"source":["### **Data Spec Check**\n","사용할 데이터 점검하기"]},{"cell_type":"markdown","source":["- **문서 읽어오기**"],"metadata":{"id":"cRiNS_3Gac5v"}},{"cell_type":"markdown","metadata":{"id":"MZymV58XKRat"},"source":["> load_and_split()과 관련된 공식 문서:\n","    - https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.pdf.PyPDFLoader.html  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snkGvGi1klnm"},"outputs":[],"source":["# PDF 파일 읽기\n","loader = PyPDFLoader(\"/content/2020_경제금융용어 700선_게시.pdf\")\n","texts = loader.load_and_split()     # 페이지별로 쪼갠다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ARp0_Hi9l8dG"},"outputs":[],"source":["# 문서의 개수(페이지 수)\n","print('✅ 문서의 수 :', len(texts))\n","\n","# 공백만 있는 페이지 등은 제외시킨다.\n","# 실질적으로 살아남는 페이지는 366page\n","# PDF 문서가 총 366개의 텍스트로 분할됨"]},{"cell_type":"markdown","source":["- **문서(텍스트) 분리하기**"],"metadata":{"id":"6deH4AdKaXOG"}},{"cell_type":"markdown","source":["> Document(metadata={'sorurce': '파일명', 'total_pages': 해당 페이지가 원래 몇 페이지였나, 'page':현재 페이지, 'page_content':'텍스트의 본문'}."],"metadata":{"id":"Ndghpk-9SLd8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3QQ86dEndkL"},"outputs":[],"source":["# 특정 페이지(텍스트) 출력하기 : 임의로 15번 문서를 출력하기\n","texts[15]\n","# texts[15].page_content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kedJwjrLjUF4"},"outputs":[],"source":["# 문서를 직접 접근하기 위해서는 .page_content를 사용.\n","print(texts[15].page_content)"]},{"cell_type":"markdown","source":["- **본문만 추출하기**"],"metadata":{"id":"xkJtShNOaSpu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9i75nevjzHL"},"outputs":[],"source":["# 각 문서의 본문만 추출하여 documents라는 변수에 저장\n","documents = [text.page_content for text in texts]\n","print(documents[15])\n","print('-' * 100)\n","print('✅ 15번 문서의 길이 :', len(documents[15]))"]},{"cell_type":"markdown","source":["- **삭제할 내용 확인**\n","    - 머릿말, 목차, 맺음말 등 경제 용어와 관련 없는 내용 삭제를 위해 확인하는 단계"],"metadata":{"id":"FWMfXrPRakpj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADfGaBMfnZJK"},"outputs":[],"source":["# 0번 문서는 머리말\n","print(texts[0].page_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NcIDwKkWZA6","collapsed":true},"outputs":[],"source":["print(texts[5].page_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wosohRdqm59D","collapsed":true},"outputs":[],"source":["# 12번 문서까지는 목차\n","print(texts[12].page_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLWudewWnK5y"},"outputs":[],"source":["# 13번 문서부터는 금융 용어 설명\n","print(texts[13].page_content)"]},{"cell_type":"markdown","metadata":{"id":"H9ZiikpvY3Xp"},"source":["참고로 \\n은 줄바꿈 문자입니다. 쉽게 설명하면 Enter에 해당하므로 크게 신경쓰지 않아도 됩니다. print()로 출력해보면 알 수 있습니다."]},{"cell_type":"markdown","source":["- **실제 필요한 부분으로 자르기**"],"metadata":{"id":"0DW-2kDaT_8E"}},{"cell_type":"markdown","metadata":{"id":"-NKtoXNRnlAl"},"source":["앞에 몇 개의 문서를 출력해본 결과 0번 문서는 머리말, 12번 문서까지는 목차, 13번 문서부터 금융 용어를 설명하는 문서임을 확인하였습니다. 다시 말해 용어를 검색을 위해서는 0번 문서부터 12번 문서는 필요가 없을 것입니다. 기존의 0번 문서와 12번 문서를 제거해보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZQDVMUvnwOP"},"outputs":[],"source":["texts = texts[13:]\n","print('✅ 줄어든 texts의 길이 :', len(texts))"]},{"cell_type":"markdown","metadata":{"id":"mSQ-JpXXqV23"},"source":["현재의 0번 문서를 출력해보겠습니다. 전처리가 제대로 되었다면 이전의 13번 문서가 현재의 0번 문서가 되어야 합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJfHhC18qQmh"},"outputs":[],"source":["print('✅ 첫번째 문서 출력 :', texts[0])"]},{"cell_type":"markdown","metadata":{"id":"5oSz1bRI1p7e"},"source":["이번에는 마지막 데이터를 확인해봅시다. 해당 문서에 대한 맺음말에 해당되므로 해당 데이터도 불필요합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d2POkH2z1kns"},"outputs":[],"source":["print(texts[-1])"]},{"cell_type":"markdown","metadata":{"id":"9MnxMYwH14Ku"},"source":["뒤에서 두번째 데이터를 확인해봅시다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRk34bCP11C1"},"outputs":[],"source":["print(texts[-2])"]},{"cell_type":"markdown","metadata":{"id":"IazT_vDE2E1H"},"source":["마지막 데이터를 제거 후에 개수를 출력해봅시다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tB0s_Ss1t98"},"outputs":[],"source":["# 마지막 데이터를 제거\n","texts = texts[:-1]\n","print('✅ 마지막 데이터 제거 후 texts의 길이 :', len(texts))"]},{"cell_type":"markdown","metadata":{"id":"341hUZf72G51"},"source":["이제 데이터의 개수가 1개 줄어들었습니다. 이제 마지막 데이터를 출력하면 앞서 출력되었던 뒤에서 두번째 데이터가 출력되어야 합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3FErojLI2Azu"},"outputs":[],"source":["print('✅ 마지막 데이터 출력')\n","texts[-1]"]},{"cell_type":"markdown","metadata":{"id":"tg3-0bim2SbN"},"source":["정리해봅시다. PyPDFLoader가 PDF를 분할하여 다수의 문서로 만들었습니다.\n","\n","1. 문서의 형태를 확인하였습니다. 형식은 page_content에는 분할된 텍스트의 본문이 저장되어져 있고, source에는 해당 본문의 원본 파일의 이름이 저장되어져 있습니다.  \n","2. PDF 페이지 371 -> 문서의 개수가 366개로 줄었습니다.\n","3. 앞의 문서와 뒤의 문서는 머리말과 맺음말인 것을 PDF 파일을 통해 확인하였으므로 실제 출력을 통해 머리말과 맺음말, 목차의 위치를 확인하고 해당 파일들을 제거하였습니다.  \n","\n","결과적으로 366개의 데이터는 352개의 데이터가 되었습니다.  \n","이제 형식을 이해하였으며 352개의 금융 문서가 있음을 알았습니다."]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"z5hhM3UXVqeG"}},{"cell_type":"markdown","metadata":{"id":"iLz7DIdL4vHV"},"source":["## **2-2.임베딩 API를 통한 문서 임베딩과 벡터 데이터베이스 적재**\n"]},{"cell_type":"markdown","source":["- **작업 내용** (벡터 데이터베이스 적재 과정)\n","    1. OpenAI **임베딩 API**를 활용해 **문서를 임베딩(유료)**하고\n","    2. 총 352개의 문서를 임베딩 API로 임베딩 진행\n","    3.**벡터 데이터베이스로 Chroma DB 사용\n","    4. 랭체인을 통한 Chroma DB 활용으로 코드를 간소화  \n","    5. 벡터 데이터베이스를 활용한 **임베딩 유사도 기반의 검색기 구현**"],"metadata":{"id":"9UOjVjeibc4o"}},{"cell_type":"markdown","metadata":{"id":"bgD2PKm0P3qC"},"source":["OpenAI Embedding API를 이용하여 텍스트를 임베딩하고, 코사인 유사도를 통해 유사한 텍스트를 가져오는 실습을 진행한 바 있습니다. 여기서는 OpenAI의 Embedding API를 사용합니다. 일반적으로 OpenAI Embedding API가 sentence_transformer 라이브러리를 이용하는 것보다 성능이 더 뛰어납니다."]},{"cell_type":"markdown","metadata":{"id":"i_d_F2KaceXK"},"source":["- **Chroma DB**\n","    - 일반적으로 Embedding하여 벡터들 간의 유사도를 구할 때에는 Vector DB라는 것을 사용함.\n","    -  Chroma DB는 이 과정들을 기능 별로 이미 구현하여 사용자가 **벡터를 좀 더 쉽게 다룰 수 있도록 도와주는 편리한 벡터 응용 도구**임\n","    - **Chroma.from_documents**()를 통해 벡터 도구 객체를 선언함. 이때 documents에는 벡터화의 단위가 될 **텍스트 리스트를 매개변수로 사용**하고, embedding에는 **어떤 종류의 임베딩을 사용할 것인지를 기재**해줌"]},{"cell_type":"markdown","metadata":{"id":"u83Xo8UZcB70"},"source":["### **크로마 사용 방법**\n","-  https://python.langchain.com/docs/integrations/vectorstores/chroma  \n","    - 링크에서 아래에 보면 'Use OpenAI Embeddings'라고 해서 OpenAI Embedding을 사용하는 경우의 예시도 제공됨"]},{"cell_type":"code","source":["# %pip install -q \"langchain-openai>=0.3.0\" \"langchain-community\" \"chromadb==1.0.21\""],"metadata":{"id":"VDn3PYhlLDw0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **텍스트 분할**"],"metadata":{"id":"l8iee1QKMJzl"}},{"cell_type":"code","source":["# 0) 라이브러리\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_community.vectorstores import Chroma\n","\n","# 1) 텍스트 분할\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=500,\n","    chunk_overlap=200,\n","    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",")\n","\n","# ✅ texts의 타입에 따라 적절한 메서드 사용\n","if isinstance(texts, list) and len(texts) > 0:\n","    if isinstance(texts[0], str):\n","        # texts가 문자열 리스트인 경우\n","        docs = text_splitter.create_documents(texts)\n","    else:\n","        # texts가 Document 객체 리스트인 경우\n","        docs = text_splitter.split_documents(texts)\n","else:\n","    raise ValueError(\"texts는 비어있지 않은 리스트여야 합니다.\")"],"metadata":{"id":"3PUSNyo5MMKx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **임베딩**: chunk_size 낮춰 한 요청 총합 300k를 넘지 않게"],"metadata":{"id":"N8_fWkCuMQ_w"}},{"cell_type":"code","source":["# 2) 임베딩: chunk_size 낮춰 한 요청 총합 300k를 넘지 않게\n","embedding = OpenAIEmbeddings(\n","    model=\"text-embedding-3-small\",\n","    max_retries=6,\n","    timeout=60,\n","    chunk_size=64\n",")"],"metadata":{"id":"d5LSdV-VMVsW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **벡터DB 생성**: 문서(texts)를 크로마DB에 적재"],"metadata":{"id":"ljJM0HDnMYSw"}},{"cell_type":"code","source":["# 3) 벡터DB 생성\n","# OpenaI 임베딩 API로 과금이 되는 부분\n","vectordb = Chroma.from_documents(\n","    documents=texts,    # 352 문서를 크로마DB에 적재됨\n","    embedding=embedding,\n","    persist_directory=\"/content/chroma_db\"\n",")\n","vectordb.persist()\n","print(\"완료! 총 청크 수:\", len(docs))"],"metadata":{"id":"8dm4OU75IWTn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **문서(texts)를 크로마DB에 적재**"],"metadata":{"id":"lUQmK-tP0B22"}},{"cell_type":"markdown","source":["- **[선택] 오류가 발생한 경우**\n","    - 원인 : 한 번의 임베딩 요청에 포함된 총 토큰 수가 300,000 한도를 넘는 경우 오류 발생\n","    - 해결방법: 토큰 단위로 덩어리(청크)를 작게 자르고, 요청을 토큰 기준으로 안전한 배치로 나눠서 넣으면 해결됨\n","    - texts"],"metadata":{"id":"G5AnKppS0UZZ"}},{"cell_type":"code","source":["# [주의!] 오류가 발생한다면 아래처럼 처리하기\n","#   한 번의 임베딩 요청에 포함된 총 토큰 수가 300,000 한도를 넘어서 오류발생함\n","'''\n","오류 메시지:\n","BadRequestError: Error code: 400 - {'error': {'message': 'Requested 376997 tokens, max 300000 tokens per request', 'type': 'max_tokens_per_request', 'param': None, 'code': 'max_tokens_per_request'}}\n","'''\n","# 처리방법\n","\n","# 1) (선택) OpenAI 임베딩 명시: 재현성과 과금 추적을 위해 모델을 명시\n","embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # 필요하면 '...-large'\n","\n","# 2) 토큰 인지형 분할기: 문서를 '토큰 기준'으로 잘게 자르기\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","# tiktoken 기반 토큰 단위 설정 (권장: 800~1,000토큰에 overlap 100)\n","text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n","    chunk_size=800,\n","    chunk_overlap=100,\n",")\n","# 만약 `texts`가 이미 LangChain의 Document 리스트라면:\n","split_docs = text_splitter.split_documents(texts)\n","\n","\n","# 3) 배치 만들기: \"요청당 총 토큰\"이 300,000 미만이 되도록 안전하게 묶기\n","import tiktoken\n","enc = tiktoken.get_encoding(\"cl100k_base\")  # OpenAI 임베딩 계열에 적합\n","\n","def token_len(doc):\n","    return len(enc.encode(doc.page_content))\n","\n","def batches_by_token(docs, max_tokens_per_req=280_000):  # 약간 여유(헤더/메타) 두고 280k 추천\n","    batch, total = [], 0\n","    for d in docs:\n","        n = token_len(d)\n","        # 혹시 단일 청크가 너무 길다면 추가 분할 필요(위 chunk_size=800이면 보통 안전)\n","        if n > max_tokens_per_req:\n","            raise ValueError(f\"단일 청크가 {n}토큰으로 너무 큽니다. chunk_size를 더 줄이세요.\")\n","        if total + n > max_tokens_per_req and batch:\n","            yield batch\n","            batch, total = [d], n\n","        else:\n","            batch.append(d); total += n\n","    if batch:\n","        yield batch\n","\n","\n","# 4) Chroma 생성 후, '안전 배치'로 나눠서 추가\n","from langchain_community.vectorstores import Chroma\n","\n","persist_dir = \"/content/chroma_db\"\n","vectordb = Chroma(embedding_function=embedding, persist_directory=persist_dir)\n","\n","num_added = 0\n","for i, batch in enumerate(batches_by_token(split_docs, max_tokens_per_req=280_000), 1):\n","    vectordb.add_documents(batch)\n","    num_added += len(batch)\n","    print(f\"[{i}] 배치 적재: {len(batch)} 개 (누적 {num_added})\")\n","\n","vectordb.persist()\n","print(\"✅ 완료. DB 경로:\", persist_dir)"],"metadata":{"id":"3XPMiQn9xuYK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **벡터 데이터베이스 내용 확인**"],"metadata":{"id":"7Pdcjtag1BRr"}},{"cell_type":"markdown","metadata":{"id":"3rcNjGeNx2B_"},"source":["vectordb를 선언하고 나면 그 후에는 '_collection' 다음에 온점을 찍고 다양한 함수들을 사용할 수 있습니다. 예를 들어 count()는 현재 저장된 문서 또는 벡터 개수를 의미합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZUj4i5Ed7P3W"},"outputs":[],"source":["# 벡터DB의 개수 확인\n","vectordb._collection.count()"]},{"cell_type":"markdown","metadata":{"id":"z-d-RB770312"},"source":["기본적으로 `_collection.get()`은 현재 vectordb에 저장된 값들을 볼 수 있게 하는 기능을 갖고 있습니다. 어떤 값들을 호출할 수 있는지 확인해봅시다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVzaqPVGJC-j"},"outputs":[],"source":["# vectordb._collection.get()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3FOn4NuK0zaR"},"outputs":[],"source":["for key in vectordb._collection.get():\n","  print(key)"]},{"cell_type":"markdown","metadata":{"id":"eqm7CdNnwyzg"},"source":["ids, embeddings, metadatas, documents를 호출할 수 있습니다. vectordb에 저장된 기존 문서들을 보고 싶다면 '['documents']'를 통해 불러올 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-MTFS1t3wuHq"},"outputs":[],"source":["# 문서 로드\n","documents = vectordb._collection.get()['documents']\n","print('✅ 문서의 개수 :', len(documents))\n","print('-' * 100)\n","print('✅ 첫번째 문서 출력 :', documents[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hw7gcFIcxilw"},"outputs":[],"source":["# embedding 호출 시도\n","result = vectordb._collection.get()['embeddings']\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"rQJiYuVKxOiv"},"source":["embedding 벡터의 값은 기본적으로는 제공하지 않기 때문에 embedding 벡터의 값도 확인하고 싶다면 get() 호출 시 내부에 include=['embeddings']를 함께 호출해야 합니다. 그 후 ['embeddings']를 통해 호출할 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6BD-NWgwH2h"},"outputs":[],"source":["# embedding vetor만 조회하기\n","embeddings = vectordb._collection.get(include=['embeddings'])['embeddings']\n","print('✅ 임베딩 벡터의 개수 :', len(embeddings))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4PIH8atwdbl"},"outputs":[],"source":["print('✅ 첫번째 문서의 임베딩 값 출력 :', embeddings[0])\n","print('✅ 첫번째 문서의 임베딩 값의 길이 :', len(embeddings[0]))\n","# openai 임베딩 API는 항상 1536개\n","# 0번 문서의 길이를 출력해보면 알 수 있다.다."]},{"cell_type":"markdown","metadata":{"id":"xdEMwxI21f8v"},"source":["이번에는 metadatas를 호출해봅시다. 참고로 metadatas는 각 문서의 출처를 의미합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGbDznct1aPR"},"outputs":[],"source":["# metadatas(각 문서의 출처)를 호출\n","metadatas = vectordb._collection.get()['metadatas']\n","print('✅ metadatas의 개수 :', len(metadatas))\n","print('✅ 첫번째 문서의 출처 :', metadatas[0])"]},{"cell_type":"markdown","source":["- **벡터DB를 이용한 검색기: as_retriever()사용**"],"metadata":{"id":"gMrJSxNU7WLU"}},{"cell_type":"markdown","metadata":{"id":"t1peZbkYP-JL"},"source":["벡터 도구 객체를 선언하고 나면 as_retriever()를 통해서 입력된 텍스트로부터 유사한 텍스트를 찾아주는 retriever를 선언할 수 있습니다. retriever를 선언 후 get_relevant_documents()를 통해 입력된 텍스트와 유사한 문서들을 찾아서 반환합니다. 앞서 실전 모델링2에서 실습했던 벡터의 유사도를 구하는 과정을 별도의 추가 구현없이 손쉽게 사용할 수 있습니다. 여기서도 내부적으로 코사인 유사도를 수행하고 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FjDEEz55lR-x"},"outputs":[],"source":["# 유사도가 높은 문서 2개만 추출. k = 2\n","retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zbeRAa_gpkwO"},"outputs":[],"source":["docs = retriever.get_relevant_documents(\"비트코인이 궁금해\")\n","print('✅ 유사 문서 개수 :', len(docs))\n","print('--' * 20)\n","print('✅ 임베딩 벡터간의 유사도가 가장 높은 문서 :', docs[0])\n","print('✅ 임베딩 벡터간의 유사도가 두번째로 높은 문서 :', docs[1])"]},{"cell_type":"markdown","source":["## **2-3.벡터 데이터베이스 검색기와 LLM 연결하기**"],"metadata":{"id":"TeaFxZlb2ovM"}},{"cell_type":"markdown","source":["- **작업 내용**\n","    - 벡터 데이터베이스 검색기와 LLM(ChatGPT) 연결하기\n","    - 프롬프트 템플릿을 활용하여 챗봇 구축하기"],"metadata":{"id":"_Wp0JTNY9MRV"}},{"cell_type":"markdown","source":["### **프롬프트 템플릿 설정하기**"],"metadata":{"id":"Xh-Rn6Xx8_Qt"}},{"cell_type":"markdown","source":["- **프롬프트 템플릿(Prompt Template)**\n","    - LLM은 텍스트를 입력으로 받는데 이런한 텍스트를 일반적으로 프롬프트라고 함\n","    - 랭체인은 프롬프트를 쉽게 구성하고 작업할 수 있도록 클래스와 함수를 제공하고 있"],"metadata":{"id":"YxP_ing89uwH"}},{"cell_type":"markdown","metadata":{"id":"ukXkbAIrQA6Z"},"source":["이제 ChatGPT API와 이미 만들어진 Prompt를 통해서 간단히 챗봇을 구현해봅시다. RetrievalQA.from_chain_type()의 llm 매개변수의 값으로 초기에 임포트한 OpenAI()를 사용할 경우, 기본값으로 ChatGPT API를 사용합니다.chain_type의 매개변수의 값으로 \"stuff\"를 사용할 경우, 사용자의 눈에는 보이지 않지만 자동으로 아래의 프롬프트를 사용하여 챗봇을 구현합니다.  \n","\n","해석해보면 주어진 질문과 본문을 통해서 답변을 하되, 만약 답변할 수 없다면 답변을 임의로 하지말고 모른다고 하라는 내용입니다.\n","```\n","Use the following pieces of context to answer the users question.\n","If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","----------------\n","{텍스트}\n","\n","{질문}\n","```"]},{"cell_type":"markdown","metadata":{"id":"HBXC89LlQGKx"},"source":["{텍스트}에는 사용자의 질문으로부터 높은 유사도를 가진 텍스트가 들어가게 되고, {질문} 부분은 사용자의 질문이 들어가게 됩니다. retriever는 입력된 사용자의 질문으로부터 유사도를 계산하는 도구를 구현하여 매개변수의 값으로 넘겨주면 됩니다. 앞서 이미 Chroma를 통해 벡터 도구 객체로부터 구현한 retreiver를 사용합니다.  \n","\n","return_source_documents는 챗봇의 답변에 사용된 텍스트들의 출처를 표시할 것인지를 의미합니다. return_source_documents의 값을 False로 할 경우, 챗봇의 답변이 어떤 텍스트에 근거하였는지 알 수 없습니다. 여기서는 뒤에서 근거가 되는 텍스트의 출처를 확인할 것이므로 True를 사용합니다."]},{"cell_type":"markdown","source":["- **프롬프트 템플릿 작성**\n","    - 특정 지시사항 적용(정체성, 대화체 등 설정)"],"metadata":{"id":"fGhTCN8a4LME"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"APp3yEVwUKly"},"outputs":[],"source":["from langchain import PromptTemplate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahQqr9GkULCG"},"outputs":[],"source":["# Create Prompt : 정체성, 대화체 설정 등\n","template = \"\"\"당신은 한국은행에서 만든 금융 용어를 설명해주는 금융챗봇입니다.\n","OOO 개발자가 만들었습니다. 주어진 검색 결과를 바탕으로 답변하세요.\n","검색 결과에 없는 내용이라면 답변할 수 없다고 하세요. 친구와 대화하듯 편한말로 친근하게 답변하세요.\n","{context}\n","\n","Question: {question}\n","Answer:\n","\"\"\"\n","\n","prompt = PromptTemplate.from_template(template)\n","\n","# {context} : 앞에서 만들어진 유사도가 높은 검색문서 2개가 여기에 들어감\n","# {question} : 사용자가 입력한 질문이 들어간다."]},{"cell_type":"markdown","source":["### **간단한 챗봇 구현하기**"],"metadata":{"id":"SsOiWpVUDBe1"}},{"cell_type":"markdown","source":["- **검색기 + 프롬프트 템플릿 + LLM 세 가지를 모두 연결**"],"metadata":{"id":"K7ArnvhW4cdQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTM-26ufqElr"},"outputs":[],"source":["# Streaming\n","# llm = ChatOpenAI(model_name=\"gpt-4o\", streaming=True, temperature=0, callbacks=[StreamingStdOutCallbackHandler()])\n","\n","# LLM을 선언, temperature=0 이면 랜덤성이 있거나 창의적인 답변은 지양()\n","llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NC1TTJIHcWma"},"outputs":[],"source":["# retriever --> RAG (앞에서 유사도가 높은 문서 2개가 지정된 상태임)\n","# 검색기 + 프롬프트 템플릿 + LLM 세 가지를 모두 연결\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    chain_type_kwargs={\"prompt\": prompt},\n","    retriever=retriever,\n","    return_source_documents=True)"]},{"cell_type":"markdown","metadata":{"id":"qaymBnlPQKHz"},"source":["이제 qa_chain을 통해 사용자의 입력으로부터 서울 청년 정책과 관련된 챗봇의 답변을 얻을 수 있습니다. 임의의 \"디커플링이란 무엇인가?\"라는 텍스트를 입력하여 qa_chain의 반환 결과를 확인해봅시다."]},{"cell_type":"markdown","source":["- **사용자 질의**"],"metadata":{"id":"07lX-Y2x5J_1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WGLr3x3eqF7o"},"outputs":[],"source":["input_text = \"디커플링이란 무엇인가?\"\n","chatbot_response = qa_chain.invoke(input_text)"]},{"cell_type":"code","source":["# chatbot_response"],"metadata":{"id":"VBIiqvtrBiU6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('✅ 사용자가 던진 질문: ', chatbot_response['query'])\n","print('✅ 사용자가 던진 질문에 대한 검색 결과: ', chatbot_response['source_documents'])\n","print('✅ 사용자가 던진 질문과 검색 결과를 바탕으로 한 답변: ', chatbot_response['result'])"],"metadata":{"id":"TfI9jd-OAv9L"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6My1QzEYisz_"},"outputs":[],"source":["input_text = \"너는 누구야?\"\n","chatbot_response = qa_chain.invoke(input_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQW9mmFS-jlD"},"outputs":[],"source":["# chatbot_response"]},{"cell_type":"code","source":["print('✅ 사용자가 던진 질문: ', chatbot_response['query'])\n","print('✅ 사용자가 던진 질문에 대한 검색 결과: ', chatbot_response['source_documents'])\n","print('✅ 사용자가 던진 질문과 검색 결과를 바탕으로 한 답변: ', chatbot_response['result'])"],"metadata":{"id":"JVGCrTRpByuk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wRuqPgu2P_o7"},"source":["\"최근의 디커플링의 예로는 금융위기 이후 신흥국가나 유로지역 국가 등이 특히 \\n미국 경제와 다른 모습을 보이는 것을 들 수 있다. 이외에도 주가나 금리, 환율 등 \\n일부 경제 변수의 흐름이 국가 간 또는 특정국가내에서 서로 다른 흐름을 보이는 현상도 \\n디커플링이라고 할 수 있다.\" 라는 문구를 활용하여 답변을 하는 것을 볼 수 있습니다.  \n","\n","이번에는 경제금융용어 700선 파일로는 알 수 없는 정보를 물어보겠습니다."]},{"cell_type":"markdown","source":["- **모델이 알지 못하는 질문하기**"],"metadata":{"id":"s-8Omai959Ix"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pcmTzUhXTPw2"},"outputs":[],"source":["input_text = \"25년 8월달의 서울 집값 추이를 알려주세요\"\n","chatbot_response = qa_chain.invoke(input_text)\n","print(chatbot_response)\n","\n","# 답변할 수 없다고 답변함"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"xsNJJHd5igLN"}},{"cell_type":"markdown","metadata":{"id":"QbMQAQy24uRk"},"source":["## **2-4.모델 테스트: Model Inference**"]},{"cell_type":"markdown","source":["- **작업 내용**\n","    - 챗봇이 사용자와 올바르게 상호작용하는지 확인하기 위한 테스트 진행\n","    - UI를 구현할 수 있는 프레임워크를 활용하여 웹상에서 챗을 구현"],"metadata":{"id":"rWxrrkQiDS9B"}},{"cell_type":"markdown","source":["- **질의응답 함수화**"],"metadata":{"id":"gKa5it2dGWEH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2njEBE5w4oVz"},"outputs":[],"source":["chatbot_response['result']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvrJfoQPqqRR"},"outputs":[],"source":["def get_chatbot_response(input_text):\n","    chatbot_response = qa_chain.invoke(input_text)\n","    return chatbot_response['result'].strip()"]},{"cell_type":"markdown","source":["- **질문 준비**: 가능한 다양한 질문으로 준비"],"metadata":{"id":"UbMWor8mGGmP"}},{"cell_type":"markdown","metadata":{"id":"6e0jirSPJBFM"},"source":["> 실제 회사에서의 업무를 수행할 때는 테스트를 위한 데이터가 아무리 적어도 최소 수십 개는 준비되어져 있어야만 합니다. 그래야만 현재의 모델이 문제가 있다고 판단되었고, 모델을 추후 개선하였을 때 동일한 테스트 데이터에 대해서 얼만큼 개선이 되었는지 정량적으로 평가가 가능하기 때문입니다.\n","\n","```\n","1. '너는 뭘하는 챗봇이니?'\n","- 챗봇을 사용하는 사용자가 반드시 물어볼 수 있는 챗봇의 역할에 대한 질문. 여기서 잘못된 답변이 나가면 사용자가 느끼는 챗봇의 성능이 크게 저하될 것이다.\n","```\n","\n","```\n","2. <최근 가장 핫한 이슈가 되는 대상>에 대해서 궁금해\n","- 사용자는 금융 용어 챗봇이라면 최근 가장 핫한 이슈가 되는 금융 용어에 대해서 질문할 가능성이 매우 높다. 예를 들어 '비트코인'을 해보자.\n","```\n","\n","```\n","3. <실제 챗봇과 직접적으로, 또 그리고 완전히 연관이 없는 대상>에 대한 문의\n","- 챗봇은 자신의 도메인을 완전히 벗어난 질문에 대해서 거짓을 말하거나 편향된 답변을 하기보다는 답변을 거부해야할 것이다.\n","```"]},{"cell_type":"markdown","source":["- **질문&결과확인**: 서비스 출시전 약 10~20개 정도 질문해본다."],"metadata":{"id":"AVUhpUlPG2S4"}},{"cell_type":"markdown","metadata":{"id":"doCgvG3gK8t0"},"source":["이번에는 실제 챗봇과의 답변을 가정하고 사용자의 질문으로부터 챗봇의 답변이 오면 해당 챗봇의 답변으로부터 이어서 사용자가 질문하는 시나리오를 진행해보겠습니다. \"너는 뭘하는 챗봇이니?\"라는 질문부터 \"비트코인에 대해서 궁금하당~\"과 같이 사용자가 할 법한 임의의 질문을 입력합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WON2tqTpKhMp"},"outputs":[],"source":["input_text = \"너는 뭘하는 챗봇이니?\"\n","result = get_chatbot_response(input_text)\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X3nX1SmSqtkW"},"outputs":[],"source":["input_text = \"비트코인에 대해서 궁금하당~\"\n","result = get_chatbot_response(input_text)\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaCHjLYxqvgO"},"outputs":[],"source":["input_text = \"EC방식에 대해서 알려줘~\"\n","result = get_chatbot_response(input_text)\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VW-Y2fVqqXF2"},"outputs":[],"source":["# 이상한 질문을 한다.--> 정치적 성향을 가진 답변을 하는지 확인\n","input_text = \"나는 보수당을 지지해야 한다고 생각해\"\n","result = get_chatbot_response(input_text)\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"9EriLlpLvUTS"},"source":["이렇게 다수의 문서로부터 질의 응답을 할 수 있는 챗봇을 구현해보았습니다. 이렇게 구현한 챗봇을 앞으로 사용할 gradio, 카카오톡이나 텔레그램 등을 연동하여 나만의 커스텀 챗봇을 구현할 수 있습니다."]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"Pn_Gm4iuHSq8"}},{"cell_type":"markdown","metadata":{"id":"FixSXFAuvl4I"},"source":["## **2-5.Model Demo**"]},{"cell_type":"markdown","metadata":{"id":"HgXuxEonbL02"},"source":["* **웹 인터페이스**\n","    * Streamlit  \n","    * Gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uyOTwcL8rUfZ"},"outputs":[],"source":["pip install gradio"]},{"cell_type":"markdown","source":["- **Gradio 사이트의 챗봇 코드 그대로 사용하기**"],"metadata":{"id":"41i7EDJmHnpy"}},{"cell_type":"markdown","metadata":{"id":"jf_jai53HtpF"},"source":["https://www.gradio.app/guides/creating-a-custom-chatbot-with-blocks"]},{"cell_type":"markdown","metadata":{"id":"5sm5x0Xvv6SQ"},"source":["위의 gradio 공식 문서 웹 사이트에서 제공하고 있는 Chatbot 코드\n","\n","```\n","import gradio as gr\n","import random\n","import time\n","\n","with gr.Blocks() as demo:\n","    chatbot = gr.Chatbot()\n","    msg = gr.Textbox()\n","    clear = gr.ClearButton([msg, chatbot])\n","\n","    def respond(message, chat_history):\n","        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n","        chat_history.append((message, bot_message))\n","        time.sleep(2)\n","        return \"\", chat_history\n","\n","    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n","\n","demo.launch()\n","```"]},{"cell_type":"markdown","source":["- 실행\n","    - 실행하고 화면 하단의 **Running on public URL: https://199cd738696c137d83.gradio.live** 부분을 클릭해서 사용한다."],"metadata":{"id":"dzhXe7erIede"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZ7PgPkufZTj"},"outputs":[],"source":["import gradio as gr\n","\n","# 인터페이스를 생성.\n","with gr.Blocks() as demo:\n","    chatbot = gr.Chatbot(label=\"경제금융용어 챗봇\") # 경제금융용어 챗봇 레이블을 좌측 상단에 구성\n","    msg = gr.Textbox(label=\"질문해주세요!\")  # 하단의 채팅창의 레이블\n","    clear = gr.Button(\"대화 초기화\")  # 대화 초기화 버튼\n","\n","    # 챗봇의 답변을 처리하는 함수\n","    def respond(message, chat_history):\n","      bot_message = get_chatbot_response(message) # 앞에서 만들어본 함수 적용\n","\n","      # 채팅 기록에 사용자의 메시지와 봇의 응답을 추가.\n","      chat_history.append((message, bot_message))\n","      return \"\", chat_history\n","\n","    # 사용자의 입력을 제출(submit)하면 respond 함수가 호출.\n","    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n","\n","    # '초기화' 버튼을 클릭하면 채팅 기록을 초기화.\n","    clear.click(lambda: None, None, chatbot, queue=False)\n","\n","# 인터페이스 실행.\n","demo.launch(debug=True)"]},{"cell_type":"markdown","metadata":{"id":"yw94UDQJm7S9"},"source":["### **결론**"]},{"cell_type":"markdown","source":["- **각자 특정 도메인에 대한 PDF 문서를 준비하고**\n","- **Langchaing + ChromaDB + OpenAI API key** 를 사용하여\n","- **도메인에 응답하는 챗봇을 만들어 볼 수 있다.**"],"metadata":{"id":"ymk_j1u7I945"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"cTCXh0Y7Pgb7"}},{"cell_type":"markdown","source":["## **[미션] 시맨틱 검색과 RAG 구현하기**\n","\n","1. 402과 501 내용 F/U\n","2. 402과 501을 참고해서 RAG 구현하기-OOO 챗봇 구현하기\n","    - 각자 OOO 챗봇을 하기 위한 OOO PDF 문서 사용하기\n","    - 사용한 OOO PDF 업로드하기"],"metadata":{"id":"sWdsUY61PhRP"}}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}